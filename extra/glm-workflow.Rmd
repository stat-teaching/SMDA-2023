---
title: "GLM Workflow"
author: "Filippo Gambarota"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Idea

These documents summarize some useful steps when analyzing a dataset with GLMs. It is important to understand that there are no fixed and correct steps but some guidelines and procedure to analyze data. Avoid thinking about absolute cut-offs, strict rules, etc. Always think about what you are doing.

# Steps

## Importing data

Despite seems a silly step, correctly importing data is fundamental.

- Check the type of data that are you importing focusing on the extension e.g. `data.csv`, `data.xlsx` etc.
- Find the appropriate function in R to import the dataset e.g. `read.csv()`
- Read the function documentation `?read.csv()` to find important argument
- Import the data and check for strange patterns

## Pre-processing

In this step is important to check if all variables are correctly interpreted by R. Numerical variables are treated as numbers? Do you want categorical variables to be factors? Are the factors levels order correctly specified according to what you want? 

- Check for columns type and convert it to your desired format
- Check for `NA` values, understand why and solve the issue (removing, imputing data, etc.)

In this step you may also consider creating new columns as the result of data transformation such as mean-centering, standardizing or general transformations.

Useful functions:

- `str()` for the dataset structure and variables class
- `summary()` for quick summary statistics
- `sapply(data, function(x) sum(is.na(x)))` how many NA values for each column

## Exploratory data analysis

This is a crucial step. Explore your dataset using the appropriate summary statistics according to the variable.

- frequency tables for categorical variables
- mean/variance/median/range for numerical variables
- plotting uni and bivariate relationships
    - scatter plots
    - boxplots
    - ...

You can use base R plots or `ggplot2`. There are multiple packages to perform these steps automatically bu the idea is to look at relationships among variables.

Clearly identify your response variables (the `y`) and possible predictors and plot/summarise the relationships `y ~ predictors`. Also relationships between predictors are important.

## Model fitting

Choose the model that you want to fit and implement it using the `glm` function. The `family` and the `link` depends on the type of variable that you have.

## Model diagnostic

Model assumptions for GLMs are not always easy to check. For example, the distribution of residuals can be misleading using **raw** residuals or when using a the **binary** version of a Binomial GLM.

Important diagnostics are:

- pearson or deviance residuals
- studentized residuals
- hatvalues
- cook distances and dfbetas

Using these measures you can identify outliers, influential observations or strange patters such as relationship between residuals and fitted values/predictors, unxepected range of residuals (e.g., overdispersion).

The residual deviance is also important to understand how the model performs compared to the null and saturated model.

Some useful functions:

- `influence.measures()` for all influence measures
- `car::residualPlots()` for residuals (specify the type)
- `car::influenceIndexPlot(vars=c("Cook", "Studentized", "hat"))` for the influence plots

## Coefficients intepretation

When interpreting parameters remember to how the model is parametrized:

- are numerical variables centered or standardized?
- which is the contrast coding for categorical variables? (e.g., dummy coding)
- are there some interactions?

When we have a lot of parameters and interactions interpreting each model coefficients can be problematic.

With interactions it is useful to use model comparison (model with and without the interaction) or the `car::Anova()` function to have the overall effect. Then the `emmeans::emmeans()` function can extract the contrast that you need.

Remember that coefficients can be interpreted both in the link-function scale and the response scale.

Useful functions:

- `car::Anova()`
- `emmeans::emmeans()`
- `predict()` to have model predictions in specific conditions
- `margins::marginal_effects()` for marginal effects
- `broom::tidy()` to extract model coefficients into a dataframe

## Plotting

Plotting is a crucial step especially with a lot of predictors and interactions. The most easy way is by using the `plot(effects::allEffects())` function.
